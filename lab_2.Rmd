---
title: "Laboratório 1 - Validação Cruzada e Seleção de Variáveis"
author: "ME905"
output: 
  pdf_document:
    fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Instruções

```{r 1-Leitura de dados}
mnist <-  read.csv('https://drive.google.com/uc?export=download&id=1cSS5BeD6NFVlzcoALicJRSt-xo-VusDj')
MNIST0178_teste <- read.csv("https://drive.google.com/uc?export=download&id=1BMq6RoV07BuNptozj86H3afLR-D2nsE3")
```

```{r 2 Visualização de Dígitos}

converte_df <- function(vetor_covariaveis){
vetor_covariaveis <- as.vector(unlist(vetor_covariaveis))
if(length(vetor_covariaveis) != 784){
stop("Passe um vetor com 784 valores!")
}
pos_x <- rep(1:28, each = 28)
pos_y <- rep(1:28, times = 28)
data.frame(pos_x, pos_y, valor = vetor_covariaveis)
}

visnum <- function(df){
df %>% ggplot(aes(x = pos_y, y = pos_x, fill = valor)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "black") +
theme_void() +
scale_y_reverse()
}

visnum(converte_df(mnist[1,2:785])) #é um 0
visnum(converte_df(mnist[3,2:785])) # é um 1
visnum(converte_df(mnist[6,2:785])) # é um 7
visnum(converte_df(mnist[7,2:785])) # é um 8
```

2a) Leia o código das funções acima e visualize as observações de número 1, 3, 6 e 7.
Que dígitos você enxerga nas imagens?

2b)Antes de ajustar qualquer modelo, quais são suas expectativas quanto à tarefa de classificação?
Entre os dígitos 0, 1, 7 e 8, quais você acredita que serão mais fáceis ou difíceis de distinguir? Justifique.

```{r 3 Árvore de Classificação com rpart}
mnist$y <- as.factor(mnist$y)

arv_decisao <- rpart(y ~. ,data = mnist)

table(predict(arv_decisao, mnist, type = "class"),mnist$y) #linhas são predições

#Previu bastante o 8 quando era 1
#Previu bastante 7 quando era 8
#Previu bastante 8 quando era 7
```

```{r 4}
Mode <- function(x) which.max(table(x))
'%!in%' <- function(x,y)!('%in%'(x,y))

random_forest <- function(ntrees,depth_tree,n_samples){
  controle <- rpart.control(maxdepth = depth_tree,minbucket = n_samples)
  predicoes <- data.frame(rep(NA,24781))
  for (i in c(1:ntrees)){
    index_var <- sample(c(2:785), size = 28,replace = F)
    index_treino <- sample(c(1:24781), size = 24781,replace = T)
    data_treino <- mnist[index_treino,c(1,index_var)]
    
    tree <- rpart(y ~ .,data = data_treino, control = controle)
    predicoes <- cbind(predicoes,predict(tree, mnist,type = "class"))
    
  }
  return(apply(predicoes,FUN = Mode,MARGIN = 1))
}


```

